\hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function}{}\doxysection{Sharp\+Neat.\+Network.\+I\+Activation\+Function Interface Reference}
\label{interface_sharp_neat_1_1_network_1_1_i_activation_function}\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}


Interface for neural network activation functions. An activation function simply takes a single input value and produces a single output value. \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function}{I\+Activation\+Function}} allows for activation functions to be plugged in to neural network implementations. Typical activation functions would be a sigmoid or step function.  


Inheritance diagram for Sharp\+Neat.\+Network.\+I\+Activation\+Function\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=12.000000cm]{interface_sharp_neat_1_1_network_1_1_i_activation_function}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
double \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6230550f91b00cf7ac384e8a885dd11a}{Calculate}} (double x, double\mbox{[}$\,$\mbox{]} aux\+Args)
\begin{DoxyCompactList}\small\item\em Calculates the output value for the specified input value and optional activation function auxiliary arguments. \end{DoxyCompactList}\item 
float \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a17e6d971ff650f3f9ab7863ce0e555c3}{Calculate}} (float x, float\mbox{[}$\,$\mbox{]} aux\+Args)
\begin{DoxyCompactList}\small\item\em Calculates the output value for the specified input value and optional activation function auxiliary arguments. This single precision overload of \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6230550f91b00cf7ac384e8a885dd11a}{Calculate()}} will be used in neural network code that has been specifically written to use floats instead of doubles. \end{DoxyCompactList}\item 
double\mbox{[}$\,$\mbox{]} \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6bf5c2eb7a6b09deb280a6e3653700db}{Get\+Random\+Aux\+Args}} (I\+Random\+Source rng, double connection\+Weight\+Range)
\begin{DoxyCompactList}\small\item\em For activation functions that accept auxiliary arguments; generates random initial values for aux arguments for newly added nodes (from an \textquotesingle{}add neuron\textquotesingle{} mutation). \end{DoxyCompactList}\item 
void \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a2943116b401f4dff51448228ec9a6b71}{Mutate\+Aux\+Args}} (double\mbox{[}$\,$\mbox{]} aux\+Args, I\+Random\+Source rng, double connection\+Weight\+Range)
\begin{DoxyCompactList}\small\item\em Genetic mutation for auxiliary argument data. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Properties}
\begin{DoxyCompactItemize}
\item 
string \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a63c74ef293a625aa7e35ce9d6dea7e2d}{Function\+Id}}\hspace{0.3cm}{\ttfamily  \mbox{[}get\mbox{]}}
\begin{DoxyCompactList}\small\item\em Gets the unique ID of the function. Stored in network X\+ML to identify which function a network or neuron is using. \end{DoxyCompactList}\item 
string \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_ad9f4086a305d232a1f099eba8794293a}{Function\+String}}\hspace{0.3cm}{\ttfamily  \mbox{[}get\mbox{]}}
\begin{DoxyCompactList}\small\item\em Gets a human readable string representation of the function. E.\+g \textquotesingle{}y=1/x\textquotesingle{}. \end{DoxyCompactList}\item 
string \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a5581e8b834a77292473b0ea23c551302}{Function\+Description}}\hspace{0.3cm}{\ttfamily  \mbox{[}get\mbox{]}}
\begin{DoxyCompactList}\small\item\em Gets a human readable verbose description of the activation function. \end{DoxyCompactList}\item 
bool \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_ad5ff022024f524777ce2c6df1ff04672}{Accepts\+Aux\+Args}}\hspace{0.3cm}{\ttfamily  \mbox{[}get\mbox{]}}
\begin{DoxyCompactList}\small\item\em Gets a flag that indicates if the activation function accepts auxiliary arguments. \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Interface for neural network activation functions. An activation function simply takes a single input value and produces a single output value. \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function}{I\+Activation\+Function}} allows for activation functions to be plugged in to neural network implementations. Typical activation functions would be a sigmoid or step function. 

The Calculate method has two overloads, one for each of the data types double and float, this allows an \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function}{I\+Activation\+Function}} object to be plugged in to neural network classes that are written to operate with either of those two data types. Typically the choice of which neural network implementation and floating point precision to use is part of the setting up and design of a problem domain and experiment. For some problem domains the extra precision of a double may be unnecessary.

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6230550f91b00cf7ac384e8a885dd11a}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6230550f91b00cf7ac384e8a885dd11a}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!Calculate@{Calculate}}
\index{Calculate@{Calculate}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{Calculate()}{Calculate()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily double Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Calculate (\begin{DoxyParamCaption}\item[{double}]{x,  }\item[{double\mbox{[}$\,$\mbox{]}}]{aux\+Args }\end{DoxyParamCaption})}



Calculates the output value for the specified input value and optional activation function auxiliary arguments. 



Implemented in \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_rbf_gaussian_a13ba8bac5bb060ee436ae4c4a8117a8a}{Sharp\+Neat.\+Network.\+Rbf\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_polynomial_approximant_steep_a71248e2a0310b18115a56060802b8a0d}{Sharp\+Neat.\+Network.\+Polynomial\+Approximant\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_quadratic_sigmoid_a3282e971aba728f564f9f15182f314de}{Sharp\+Neat.\+Network.\+Quadratic\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_soft_sign_steep_a3cb1bcb3f35732874a42b507f3203fd7}{Sharp\+Neat.\+Network.\+Soft\+Sign\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_gaussian_aa24fa03c73015b7e937a4341d7d77736}{Sharp\+Neat.\+Network.\+Bipolar\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_gaussian_a329fb4012f4c63592e7d3eef3aceba55}{Sharp\+Neat.\+Network.\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_sigmoid_a837c4269f092b93ddf7433a6dc3bf622}{Sharp\+Neat.\+Network.\+Bipolar\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_linear_a724d8bb23211b76bc4f44792b586d99a}{Sharp\+Neat.\+Network.\+Linear}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_sine_a3894f8ea9942f3cfeea0863670b301e3}{Sharp\+Neat.\+Network.\+Sine}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_a3e30ce9a829d6d5f172cebc95bfb9241}{Sharp\+Neat.\+Network.\+Logistic\+Function}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_steep_a38f7d9e627117879c18587969325d9bd}{Sharp\+Neat.\+Network.\+Logistic\+Function\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_null_fn_a672a5eea83267fbe1274a1539c314cb1}{Sharp\+Neat.\+Network.\+Null\+Fn}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_scaled_e_l_u_ae5104615f87eadcbe27704e47b982547}{Sharp\+Neat.\+Network.\+Scaled\+E\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_a4612230cdbd52da8c8cf08bc8b560015}{Sharp\+Neat.\+Network.\+S\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_shifted_aab5b1d6f6a56e23686168dc4d9b60ce0}{Sharp\+Neat.\+Network.\+S\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_sin_h_a30c70469017ca89851142a6d8831ecb5}{Sharp\+Neat.\+Network.\+Arc\+SinH}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_shifted_a569ae6c68f04405310952bb0418eb23a}{Sharp\+Neat.\+Network.\+Leaky\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_max_minus_one_af30adce5e873b64c3b307991decb497a}{Sharp\+Neat.\+Network.\+Max\+Minus\+One}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_a2419d9f8f8b3f2435c8cf10636ce5e39}{Sharp\+Neat.\+Network.\+Leaky\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_re_l_u_a2035a931b6b4c74d463a6a73b5f5df4c}{Sharp\+Neat.\+Network.\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_tan_a538565fcde220fe51da4f3ec90a90b1b}{Sharp\+Neat.\+Network.\+Arc\+Tan}}, and \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_tan_h_aa1d79f456b07afaedef7f2c90c40dbb1}{Sharp\+Neat.\+Network.\+TanH}}.

\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_a17e6d971ff650f3f9ab7863ce0e555c3}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_a17e6d971ff650f3f9ab7863ce0e555c3}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!Calculate@{Calculate}}
\index{Calculate@{Calculate}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{Calculate()}{Calculate()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily float Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Calculate (\begin{DoxyParamCaption}\item[{float}]{x,  }\item[{float\mbox{[}$\,$\mbox{]}}]{aux\+Args }\end{DoxyParamCaption})}



Calculates the output value for the specified input value and optional activation function auxiliary arguments. This single precision overload of \mbox{\hyperlink{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6230550f91b00cf7ac384e8a885dd11a}{Calculate()}} will be used in neural network code that has been specifically written to use floats instead of doubles. 



Implemented in \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_rbf_gaussian_a8df1e079d9e7240b568b9302b9869cff}{Sharp\+Neat.\+Network.\+Rbf\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_polynomial_approximant_steep_ae4cc5b89b8c49359e2de007d51f543aa}{Sharp\+Neat.\+Network.\+Polynomial\+Approximant\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_quadratic_sigmoid_a0052af6f56ecf8baca691818c8949987}{Sharp\+Neat.\+Network.\+Quadratic\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_linear_a8799f818b13d6e181fb8cfd2a2544559}{Sharp\+Neat.\+Network.\+Linear}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_soft_sign_steep_ab58dd3f6c27a1a2b156db289feb9d0c9}{Sharp\+Neat.\+Network.\+Soft\+Sign\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_gaussian_afff2fbcf8711cfe6f77dc35581ad2b60}{Sharp\+Neat.\+Network.\+Bipolar\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_gaussian_a609a38abdf5af235cf783c0b2a2bc25f}{Sharp\+Neat.\+Network.\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_sigmoid_adfab36bc1d0b4cabfeaf387886f9706c}{Sharp\+Neat.\+Network.\+Bipolar\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_sine_a7392e67ba7878955199506b15c702544}{Sharp\+Neat.\+Network.\+Sine}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_a2d544fb80e425b1ad121b875f9e5688f}{Sharp\+Neat.\+Network.\+Logistic\+Function}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_steep_a5644cbc8a69b0264826985943d109158}{Sharp\+Neat.\+Network.\+Logistic\+Function\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_null_fn_ae98b24a71b707decef667eecceb24264}{Sharp\+Neat.\+Network.\+Null\+Fn}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_scaled_e_l_u_aa1e4b04bdea71badbfd536042e56e751}{Sharp\+Neat.\+Network.\+Scaled\+E\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_shifted_a11d18332b5ef19c79855146f5ebfc21e}{Sharp\+Neat.\+Network.\+S\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_a63cfe2b5385a0727fef7f8cb2e746004}{Sharp\+Neat.\+Network.\+S\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_shifted_a0f3f79773c3dd95d507a585ce966d33c}{Sharp\+Neat.\+Network.\+Leaky\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_ae41a36f47a2e73249b230b0731f921c4}{Sharp\+Neat.\+Network.\+Leaky\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_max_minus_one_a352244a798c4a02bc3dde0c00bcaab9e}{Sharp\+Neat.\+Network.\+Max\+Minus\+One}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_re_l_u_a7a7cf526a2c169c2407750e74f4be7e2}{Sharp\+Neat.\+Network.\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_sin_h_ae6d74f711ea4927894ab5253c55258d6}{Sharp\+Neat.\+Network.\+Arc\+SinH}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_tan_a065e102231206e1b76d6dcf3c662e0f8}{Sharp\+Neat.\+Network.\+Arc\+Tan}}, and \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_tan_h_a39d816ab83b16f52b33857912e7df5c4}{Sharp\+Neat.\+Network.\+TanH}}.

\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6bf5c2eb7a6b09deb280a6e3653700db}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_a6bf5c2eb7a6b09deb280a6e3653700db}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!GetRandomAuxArgs@{GetRandomAuxArgs}}
\index{GetRandomAuxArgs@{GetRandomAuxArgs}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{GetRandomAuxArgs()}{GetRandomAuxArgs()}}
{\footnotesize\ttfamily double \mbox{[}$\,$\mbox{]} Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Get\+Random\+Aux\+Args (\begin{DoxyParamCaption}\item[{I\+Random\+Source}]{rng,  }\item[{double}]{connection\+Weight\+Range }\end{DoxyParamCaption})}



For activation functions that accept auxiliary arguments; generates random initial values for aux arguments for newly added nodes (from an \textquotesingle{}add neuron\textquotesingle{} mutation). 



Implemented in \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_quadratic_sigmoid_a04e7ea87426853e5015aad12236a3621}{Sharp\+Neat.\+Network.\+Quadratic\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_polynomial_approximant_steep_a26e2bce98543337bda5679d1597b9cff}{Sharp\+Neat.\+Network.\+Polynomial\+Approximant\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_rbf_gaussian_aa6ffe92a37b41e9656cce30959f4b913}{Sharp\+Neat.\+Network.\+Rbf\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_linear_a96c541182acaec4aa2123ba6a08b34a9}{Sharp\+Neat.\+Network.\+Linear}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_soft_sign_steep_a0ca294f3166ff4714b2ea1de04c9ccaf}{Sharp\+Neat.\+Network.\+Soft\+Sign\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_gaussian_a0ee5bf2871cbe231fc9d7c3cf4c3121e}{Sharp\+Neat.\+Network.\+Bipolar\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_gaussian_a973fb294dddd7951b3e50068b001bf00}{Sharp\+Neat.\+Network.\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_sigmoid_a16126ee75e3c1277d7a1ffa2022b17ea}{Sharp\+Neat.\+Network.\+Bipolar\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_sine_a2bb9e202ae1bf35df2facd842f7085ba}{Sharp\+Neat.\+Network.\+Sine}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_a5ee5ed8279389813022be7ef7e0e56f6}{Sharp\+Neat.\+Network.\+Logistic\+Function}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_steep_a543dd8c17c669114894f52bc1f43da98}{Sharp\+Neat.\+Network.\+Logistic\+Function\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_null_fn_ab13ca5ada9eda755df8146808f6c5d4b}{Sharp\+Neat.\+Network.\+Null\+Fn}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_shifted_a45d8b257fc582204030d25590d275561}{Sharp\+Neat.\+Network.\+S\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_a2ebb8e7fb16703a8bd9cee8987c61d1d}{Sharp\+Neat.\+Network.\+S\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_scaled_e_l_u_a98d7f4c2e58b215f4fefefda11a5f33c}{Sharp\+Neat.\+Network.\+Scaled\+E\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_shifted_ad236b47053f4f68a418a45986d02f128}{Sharp\+Neat.\+Network.\+Leaky\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_a6a906cf8759c0af459893814d5971c2b}{Sharp\+Neat.\+Network.\+Leaky\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_max_minus_one_ac66fbe22cbf8298a8c2d0fbca1302331}{Sharp\+Neat.\+Network.\+Max\+Minus\+One}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_re_l_u_a34f25b60af075a514850d36c21bd2878}{Sharp\+Neat.\+Network.\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_sin_h_a41398931fe4813b947768bdacc578a38}{Sharp\+Neat.\+Network.\+Arc\+SinH}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_tan_ae5c60538e68c9931608edd9bddf8ce6c}{Sharp\+Neat.\+Network.\+Arc\+Tan}}, and \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_tan_h_abc2c87e1445c2053048d8d3fad038d26}{Sharp\+Neat.\+Network.\+TanH}}.

\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_a2943116b401f4dff51448228ec9a6b71}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_a2943116b401f4dff51448228ec9a6b71}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!MutateAuxArgs@{MutateAuxArgs}}
\index{MutateAuxArgs@{MutateAuxArgs}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{MutateAuxArgs()}{MutateAuxArgs()}}
{\footnotesize\ttfamily void Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Mutate\+Aux\+Args (\begin{DoxyParamCaption}\item[{double\mbox{[}$\,$\mbox{]}}]{aux\+Args,  }\item[{I\+Random\+Source}]{rng,  }\item[{double}]{connection\+Weight\+Range }\end{DoxyParamCaption})}



Genetic mutation for auxiliary argument data. 



Implemented in \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_quadratic_sigmoid_ac3602f067c87c3c3e1be8f83e87b4fd5}{Sharp\+Neat.\+Network.\+Quadratic\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_rbf_gaussian_a024a4dfec2d6edab4251f2f1b8766d1b}{Sharp\+Neat.\+Network.\+Rbf\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_polynomial_approximant_steep_a6baa1a15140c0d49f48ab2822bca4466}{Sharp\+Neat.\+Network.\+Polynomial\+Approximant\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_linear_a4f3692da1e1ea8aad19c265ef13f03bb}{Sharp\+Neat.\+Network.\+Linear}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_soft_sign_steep_ae21da48cd6264dfb10bb470f2a388a26}{Sharp\+Neat.\+Network.\+Soft\+Sign\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_gaussian_afb3ed85785751b496cd9eb91666f3852}{Sharp\+Neat.\+Network.\+Bipolar\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_gaussian_a5930ce6d2592813b73b8e9f47b173a3f}{Sharp\+Neat.\+Network.\+Gaussian}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_bipolar_sigmoid_a87a7a2ed6d7f833e18fe35056354e3a3}{Sharp\+Neat.\+Network.\+Bipolar\+Sigmoid}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_sine_aa05763e08202b5714f6cb6a4e1e36ba7}{Sharp\+Neat.\+Network.\+Sine}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_ab6c2ed8d1d3541bad5eedd22f7921367}{Sharp\+Neat.\+Network.\+Logistic\+Function}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_logistic_function_steep_ac6580adcccb89fd65b3781a5e1cd289c}{Sharp\+Neat.\+Network.\+Logistic\+Function\+Steep}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_null_fn_a989dbc2df6885ee8f461251439d31f93}{Sharp\+Neat.\+Network.\+Null\+Fn}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_shifted_a6a5d55536ac3281790581b6d981a670a}{Sharp\+Neat.\+Network.\+S\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_s_re_l_u_ac6d84ea80a067f4a74e6c48a40cfba37}{Sharp\+Neat.\+Network.\+S\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_scaled_e_l_u_a0cde810468052db41b54cfbd173b3e2f}{Sharp\+Neat.\+Network.\+Scaled\+E\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_shifted_a343bee6ab56636796bd9a78f6acc5484}{Sharp\+Neat.\+Network.\+Leaky\+Re\+L\+U\+Shifted}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_leaky_re_l_u_a76776e42fa2e210d387a5b3f45d5a229}{Sharp\+Neat.\+Network.\+Leaky\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_max_minus_one_a68d827af6c1077b753cf2c5639b703fa}{Sharp\+Neat.\+Network.\+Max\+Minus\+One}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_re_l_u_a182e73f2f35e978c7b6689cb2f99b3b0}{Sharp\+Neat.\+Network.\+Re\+LU}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_sin_h_a62d1ba3d15b52915aaede1ecac0ea17e}{Sharp\+Neat.\+Network.\+Arc\+SinH}}, \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_arc_tan_aef1b1316ed9f3d4f0ad494920ab4a7be}{Sharp\+Neat.\+Network.\+Arc\+Tan}}, and \mbox{\hyperlink{class_sharp_neat_1_1_network_1_1_tan_h_aa70c8cc6d41e784fb5e2071e890dfe66}{Sharp\+Neat.\+Network.\+TanH}}.



\doxysubsection{Property Documentation}
\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_ad5ff022024f524777ce2c6df1ff04672}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_ad5ff022024f524777ce2c6df1ff04672}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!AcceptsAuxArgs@{AcceptsAuxArgs}}
\index{AcceptsAuxArgs@{AcceptsAuxArgs}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{AcceptsAuxArgs}{AcceptsAuxArgs}}
{\footnotesize\ttfamily bool Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Accepts\+Aux\+Args\hspace{0.3cm}{\ttfamily [get]}}



Gets a flag that indicates if the activation function accepts auxiliary arguments. 

\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_a5581e8b834a77292473b0ea23c551302}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_a5581e8b834a77292473b0ea23c551302}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!FunctionDescription@{FunctionDescription}}
\index{FunctionDescription@{FunctionDescription}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{FunctionDescription}{FunctionDescription}}
{\footnotesize\ttfamily string Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Function\+Description\hspace{0.3cm}{\ttfamily [get]}}



Gets a human readable verbose description of the activation function. 

\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_a63c74ef293a625aa7e35ce9d6dea7e2d}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_a63c74ef293a625aa7e35ce9d6dea7e2d}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!FunctionId@{FunctionId}}
\index{FunctionId@{FunctionId}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{FunctionId}{FunctionId}}
{\footnotesize\ttfamily string Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Function\+Id\hspace{0.3cm}{\ttfamily [get]}}



Gets the unique ID of the function. Stored in network X\+ML to identify which function a network or neuron is using. 

\mbox{\Hypertarget{interface_sharp_neat_1_1_network_1_1_i_activation_function_ad9f4086a305d232a1f099eba8794293a}\label{interface_sharp_neat_1_1_network_1_1_i_activation_function_ad9f4086a305d232a1f099eba8794293a}} 
\index{SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}!FunctionString@{FunctionString}}
\index{FunctionString@{FunctionString}!SharpNeat.Network.IActivationFunction@{SharpNeat.Network.IActivationFunction}}
\doxysubsubsection{\texorpdfstring{FunctionString}{FunctionString}}
{\footnotesize\ttfamily string Sharp\+Neat.\+Network.\+I\+Activation\+Function.\+Function\+String\hspace{0.3cm}{\ttfamily [get]}}



Gets a human readable string representation of the function. E.\+g \textquotesingle{}y=1/x\textquotesingle{}. 



The documentation for this interface was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Sharp\+Neat\+Lib/\+Network/I\+Activation\+Function.\+cs\end{DoxyCompactItemize}

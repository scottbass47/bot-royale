\hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted}{}\doxysection{Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Leaky\+Re\+L\+U\+Shifted Class Reference}
\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted}\index{SharpNeat.NeuralNet.Double.ActivationFunctions.LeakyReLUShifted@{SharpNeat.NeuralNet.Double.ActivationFunctions.LeakyReLUShifted}}


Leaky rectified linear activation unit (\mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_re_l_u}{Re\+LU}}). Shifted on the x-\/axis so that x=0 gives y=0.\+5, in keeping with the logistic sigmoid.  


Inheritance diagram for Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Leaky\+Re\+L\+U\+Shifted\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_a8f05b8d2bda1b1a7896ec95c68883cb0}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_a8f05b8d2bda1b1a7896ec95c68883cb0}} 
double {\bfseries Fn} (double x)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_a0044fec89023027b48f338bf522995c6}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_a0044fec89023027b48f338bf522995c6}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_ad90e9e0b3e99bcf7fd27448b327afe03}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_ad90e9e0b3e99bcf7fd27448b327afe03}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, int start\+Idx, int end\+Idx)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_a7f137f10bc71a7bf81d81e2d050cb863}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_leaky_re_l_u_shifted_a7f137f10bc71a7bf81d81e2d050cb863}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, double\mbox{[}$\,$\mbox{]} w, int start\+Idx, int end\+Idx)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Leaky rectified linear activation unit (\mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_re_l_u}{Re\+LU}}). Shifted on the x-\/axis so that x=0 gives y=0.\+5, in keeping with the logistic sigmoid. 



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Sharp\+Neat\+Lib/\+Neural\+Net/\+Double/\+Activation\+Functions/Leaky\+Re\+L\+U\+Shifted.\+cs\end{DoxyCompactItemize}

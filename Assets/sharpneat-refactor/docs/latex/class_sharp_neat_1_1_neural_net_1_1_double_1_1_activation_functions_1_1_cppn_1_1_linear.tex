\hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear}{}\doxysection{Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Cppn.\+Linear Class Reference}
\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear}\index{SharpNeat.NeuralNet.Double.ActivationFunctions.Cppn.Linear@{SharpNeat.NeuralNet.Double.ActivationFunctions.Cppn.Linear}}


\mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear}{Linear}} activation function with clipping. By \textquotesingle{}clipping\textquotesingle{} we mean the output value is linear between x = -\/1 and x = 1. Below -\/1 and above +1 the output is clipped at -\/1 and +1 respectively.  


Inheritance diagram for Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Cppn.\+Linear\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_aa288b40abad14f0900647598d59c456a}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_aa288b40abad14f0900647598d59c456a}} 
double {\bfseries Fn} (double x)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_a1d1fce882da93a1971674092305ef733}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_a1d1fce882da93a1971674092305ef733}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_aed0d1ddc77ad199a7c49ceefe15ea78c}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_aed0d1ddc77ad199a7c49ceefe15ea78c}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, int start\+Idx, int end\+Idx)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_af9465d3142eef5d1d59768c476b503e0}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear_af9465d3142eef5d1d59768c476b503e0}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, double\mbox{[}$\,$\mbox{]} w, int start\+Idx, int end\+Idx)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_cppn_1_1_linear}{Linear}} activation function with clipping. By \textquotesingle{}clipping\textquotesingle{} we mean the output value is linear between x = -\/1 and x = 1. Below -\/1 and above +1 the output is clipped at -\/1 and +1 respectively. 



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Sharp\+Neat\+Lib/\+Neural\+Net/\+Double/\+Activation\+Functions/\+Cppn/Linear.\+cs\end{DoxyCompactItemize}

\hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep}{}\doxysection{Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Soft\+Sign\+Steep Class Reference}
\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep}\index{SharpNeat.NeuralNet.Double.ActivationFunctions.SoftSignSteep@{SharpNeat.NeuralNet.Double.ActivationFunctions.SoftSignSteep}}


The softsign sigmoid. This is a variant of softsign that has a steeper slope at and around the origin that is intended to be a similar slope to that of Logistic\+Function\+Steep.  


Inheritance diagram for Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Soft\+Sign\+Steep\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
double \mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a4a895e7feb1dae953ba9e05ad4d14e70}{Fn}} (double x)
\begin{DoxyCompactList}\small\item\em Calculates the output value for the specified input value. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_adb522c53df6532c72fa3d9890b3e37e2}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_adb522c53df6532c72fa3d9890b3e37e2}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a85f799580bcf65f940673026165ce685}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a85f799580bcf65f940673026165ce685}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, int start\+Idx, int end\+Idx)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a9cac6e0b8946a8f8a676f8a5e470b549}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a9cac6e0b8946a8f8a676f8a5e470b549}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, double\mbox{[}$\,$\mbox{]} w, int start\+Idx, int end\+Idx)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
The softsign sigmoid. This is a variant of softsign that has a steeper slope at and around the origin that is intended to be a similar slope to that of Logistic\+Function\+Steep. 



\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a4a895e7feb1dae953ba9e05ad4d14e70}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_soft_sign_steep_a4a895e7feb1dae953ba9e05ad4d14e70}} 
\index{SharpNeat.NeuralNet.Double.ActivationFunctions.SoftSignSteep@{SharpNeat.NeuralNet.Double.ActivationFunctions.SoftSignSteep}!Fn@{Fn}}
\index{Fn@{Fn}!SharpNeat.NeuralNet.Double.ActivationFunctions.SoftSignSteep@{SharpNeat.NeuralNet.Double.ActivationFunctions.SoftSignSteep}}
\doxysubsubsection{\texorpdfstring{Fn()}{Fn()}}
{\footnotesize\ttfamily double Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Soft\+Sign\+Steep.\+Fn (\begin{DoxyParamCaption}\item[{double}]{x }\end{DoxyParamCaption})}



Calculates the output value for the specified input value. 



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Sharp\+Neat\+Lib/\+Neural\+Net/\+Double/\+Activation\+Functions/Soft\+Sign\+Steep.\+cs\end{DoxyCompactItemize}

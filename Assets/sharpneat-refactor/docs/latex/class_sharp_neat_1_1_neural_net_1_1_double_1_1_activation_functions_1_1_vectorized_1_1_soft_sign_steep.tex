\hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep}{}\doxysection{Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Vectorized.\+Soft\+Sign\+Steep Class Reference}
\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep}\index{SharpNeat.NeuralNet.Double.ActivationFunctions.Vectorized.SoftSignSteep@{SharpNeat.NeuralNet.Double.ActivationFunctions.Vectorized.SoftSignSteep}}


The softsign sigmoid. This is a variant of softsign that has a steeper slope at and around the origin that is intended to be a similar slope to that of Logistic\+Function\+Steep.  


Inheritance diagram for Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Vectorized.\+Soft\+Sign\+Steep\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
double \mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_aa2b50901744e6fdb909aaf6f35d7fad9}{Fn}} (double x)
\begin{DoxyCompactList}\small\item\em Calculates the output value for the specified input value. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_a8a421ad4c07a16febc8b218ffd309447}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_a8a421ad4c07a16febc8b218ffd309447}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_afff9526f399c3f18633c54f0c3276f22}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_afff9526f399c3f18633c54f0c3276f22}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, int start\+Idx, int end\+Idx)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_a598ad099f520c766e0fcac29de30c99f}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_a598ad099f520c766e0fcac29de30c99f}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, double\mbox{[}$\,$\mbox{]} w, int start\+Idx, int end\+Idx)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
The softsign sigmoid. This is a variant of softsign that has a steeper slope at and around the origin that is intended to be a similar slope to that of Logistic\+Function\+Steep. 



\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_aa2b50901744e6fdb909aaf6f35d7fad9}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_vectorized_1_1_soft_sign_steep_aa2b50901744e6fdb909aaf6f35d7fad9}} 
\index{SharpNeat.NeuralNet.Double.ActivationFunctions.Vectorized.SoftSignSteep@{SharpNeat.NeuralNet.Double.ActivationFunctions.Vectorized.SoftSignSteep}!Fn@{Fn}}
\index{Fn@{Fn}!SharpNeat.NeuralNet.Double.ActivationFunctions.Vectorized.SoftSignSteep@{SharpNeat.NeuralNet.Double.ActivationFunctions.Vectorized.SoftSignSteep}}
\doxysubsubsection{\texorpdfstring{Fn()}{Fn()}}
{\footnotesize\ttfamily double Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+Vectorized.\+Soft\+Sign\+Steep.\+Fn (\begin{DoxyParamCaption}\item[{double}]{x }\end{DoxyParamCaption})}



Calculates the output value for the specified input value. 



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Sharp\+Neat\+Lib/\+Neural\+Net/\+Double/\+Activation\+Functions/\+Vectorized/Soft\+Sign\+Steep.\+cs\end{DoxyCompactItemize}

\hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted}{}\doxysection{Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+S\+Re\+L\+U\+Shifted Class Reference}
\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted}\index{SharpNeat.NeuralNet.Double.ActivationFunctions.SReLUShifted@{SharpNeat.NeuralNet.Double.ActivationFunctions.SReLUShifted}}


S-\/shaped rectified linear activation unit (\mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u}{S\+Re\+LU}}). Shifted on the x-\/axis so that x=0 gives y=0.\+5, in keeping with the logistic sigmoid. From\+: \href{https://en.wikipedia.org/wiki/Activation_function}{\texttt{ https\+://en.\+wikipedia.\+org/wiki/\+Activation\+\_\+function}} \href{https://arxiv.org/abs/1512.07030}{\texttt{ https\+://arxiv.\+org/abs/1512.\+07030}} \mbox{[}Deep Learning with S-\/shaped Rectified Linear Activation Units\mbox{]}  


Inheritance diagram for Sharp\+Neat.\+Neural\+Net.\+Double.\+Activation\+Functions.\+S\+Re\+L\+U\+Shifted\+:\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=2.000000cm]{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_af8b939e96325da734343e4b3d8d4661d}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_af8b939e96325da734343e4b3d8d4661d}} 
double {\bfseries Fn} (double x)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_a49fbe92ccf555545703e246a3227cf49}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_a49fbe92ccf555545703e246a3227cf49}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_a7c74db47bf01e9c3552b10c518a23a89}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_a7c74db47bf01e9c3552b10c518a23a89}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, int start\+Idx, int end\+Idx)
\item 
\mbox{\Hypertarget{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_a64552bed9984e1feb1a0a3f9998104a6}\label{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u_shifted_a64552bed9984e1feb1a0a3f9998104a6}} 
void {\bfseries Fn} (double\mbox{[}$\,$\mbox{]} v, double\mbox{[}$\,$\mbox{]} w, int start\+Idx, int end\+Idx)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
S-\/shaped rectified linear activation unit (\mbox{\hyperlink{class_sharp_neat_1_1_neural_net_1_1_double_1_1_activation_functions_1_1_s_re_l_u}{S\+Re\+LU}}). Shifted on the x-\/axis so that x=0 gives y=0.\+5, in keeping with the logistic sigmoid. From\+: \href{https://en.wikipedia.org/wiki/Activation_function}{\texttt{ https\+://en.\+wikipedia.\+org/wiki/\+Activation\+\_\+function}} \href{https://arxiv.org/abs/1512.07030}{\texttt{ https\+://arxiv.\+org/abs/1512.\+07030}} \mbox{[}Deep Learning with S-\/shaped Rectified Linear Activation Units\mbox{]} 



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/\+Sharp\+Neat\+Lib/\+Neural\+Net/\+Double/\+Activation\+Functions/S\+Re\+L\+U\+Shifted.\+cs\end{DoxyCompactItemize}

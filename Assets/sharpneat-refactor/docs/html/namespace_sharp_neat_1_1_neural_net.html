<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>SharpNEAT: SharpNeat.NeuralNet Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">SharpNEAT
   </div>
   <div id="projectbrief">C# implementation of NEAT</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('namespace_sharp_neat_1_1_neural_net.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#namespaces">Namespaces</a> &#124;
<a href="#nested-classes">Classes</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">SharpNeat.NeuralNet Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sharp_neat_1_1_neural_net_1_1_default_activation_function_factory.html">DefaultActivationFunctionFactory</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default implementation of IActivationFunctionFactory&lt;T&gt;.  <a href="class_sharp_neat_1_1_neural_net_1_1_default_activation_function_factory.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">interface &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="interface_sharp_neat_1_1_neural_net_1_1_i_activation_function.html">IActivationFunction</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Neural net node activation function.  <a href="interface_sharp_neat_1_1_neural_net_1_1_i_activation_function.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">interface &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="interface_sharp_neat_1_1_neural_net_1_1_i_activation_function_factory.html">IActivationFunctionFactory</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Represents a factory for obtaining instances of IActivationFunction&lt;T&gt;.  <a href="interface_sharp_neat_1_1_neural_net_1_1_i_activation_function_factory.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sharp_neat_1_1_neural_net_1_1_network_activation_scheme.html">NetworkActivationScheme</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Represents network activation schemes.  <a href="class_sharp_neat_1_1_neural_net_1_1_network_activation_scheme.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:a27ff9f8b81855c4d5fc8cef8b0f72de3"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3">ActivationFunctionId</a> { <br />
&#160;&#160;<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3ab15819524466d41b2114dc91630edc0c">ActivationFunctionId.ArcSinH</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3aceffe7f812563934924b8dd08a319fc7">ActivationFunctionId.ArcTan</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3abb7ba525e0c40179fab22b4f7021e1f8">ActivationFunctionId.LeakyReLU</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3abf418518814d00feae3c57abdb42ed33">ActivationFunctionId.LeakyReLUShifted</a>, 
<br />
&#160;&#160;<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a9a2126552a9de60d20d95a47f85a16fd">ActivationFunctionId.Logistic</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3af332fa7e3bdba9d6626b2b0fa81ff750">ActivationFunctionId.LogisticApproximantSteep</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a2aec9459f1ea9e144c3df7f96a2a080d">ActivationFunctionId.LogisticSteep</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a185bbed8eed73247c37f61fe6af0c73a">ActivationFunctionId.MaxMinusOne</a>, 
<br />
&#160;&#160;<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a7ee44e8257ec8046f96bb86a6c5837ec">ActivationFunctionId.NullFn</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a07cade9a2910a2401165771a815bb7bd">ActivationFunctionId.PolynomialApproximantSteep</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a42dfb5214fde625aa0b9daa25fa48745">ActivationFunctionId.QuadraticSigmoid</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3add10d919fa85cf27fc78c0e06fe0b378">ActivationFunctionId.ReLU</a>, 
<br />
&#160;&#160;<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a507397d2e79e077181748788413cf0e1">ActivationFunctionId.ScaledELU</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a9a2993b063c53c9152efc379d854233c">ActivationFunctionId.SoftSignSteep</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3aa56102aa4851a1dbb5279c6a73b3c439">ActivationFunctionId.SReLU</a>, 
<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a47015ed4ddc5087547e16930ddfce10e">ActivationFunctionId.SReLUShifted</a>, 
<br />
&#160;&#160;<a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3a23b68da1de2b77d74da9da2635722a3e">ActivationFunctionId.TanH</a>
<br />
 }</td></tr>
<tr class="memdesc:a27ff9f8b81855c4d5fc8cef8b0f72de3"><td class="mdescLeft">&#160;</td><td class="mdescRight">The set of neural network activation functions provided as standard in SharpNEAT.  <a href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3">More...</a><br /></td></tr>
<tr class="separator:a27ff9f8b81855c4d5fc8cef8b0f72de3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a07799c995b8a60aa890f0ed13957ea5f"><td class="memItemLeft" align="right" valign="top">delegate void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a07799c995b8a60aa890f0ed13957ea5f">VecFn&lt; T &gt;</a> (T[] v)</td></tr>
<tr class="memdesc:a07799c995b8a60aa890f0ed13957ea5f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vectorized activation function.  <a href="namespace_sharp_neat_1_1_neural_net.html#a07799c995b8a60aa890f0ed13957ea5f">More...</a><br /></td></tr>
<tr class="separator:a07799c995b8a60aa890f0ed13957ea5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24d800421b54ea3542656b8139caa263"><td class="memItemLeft" align="right" valign="top">delegate void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a24d800421b54ea3542656b8139caa263">VecFnSegment&lt; T &gt;</a> (double[] v, int startIdx, int endIdx)</td></tr>
<tr class="memdesc:a24d800421b54ea3542656b8139caa263"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vectorized activation function with activity limited to a defined sub-range/segment of the vector.  <a href="namespace_sharp_neat_1_1_neural_net.html#a24d800421b54ea3542656b8139caa263">More...</a><br /></td></tr>
<tr class="separator:a24d800421b54ea3542656b8139caa263"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad5f51a21485ae71aeec537c68ab11026"><td class="memItemLeft" align="right" valign="top">delegate void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespace_sharp_neat_1_1_neural_net.html#ad5f51a21485ae71aeec537c68ab11026">VecFnSegment2&lt; T &gt;</a> (double[] v, double[] w, int startIdx, int endIdx)</td></tr>
<tr class="memdesc:ad5f51a21485ae71aeec537c68ab11026"><td class="mdescLeft">&#160;</td><td class="mdescRight">Vectorized activation function with activity limited to a defined sub-range/segment of the vector, and post-activation levels stored in a separate supplied vector.  <a href="namespace_sharp_neat_1_1_neural_net.html#ad5f51a21485ae71aeec537c68ab11026">More...</a><br /></td></tr>
<tr class="separator:ad5f51a21485ae71aeec537c68ab11026"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="a27ff9f8b81855c4d5fc8cef8b0f72de3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27ff9f8b81855c4d5fc8cef8b0f72de3">&#9670;&nbsp;</a></span>ActivationFunctionId</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="namespace_sharp_neat_1_1_neural_net.html#a27ff9f8b81855c4d5fc8cef8b0f72de3">SharpNeat.NeuralNet.ActivationFunctionId</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The set of neural network activation functions provided as standard in SharpNEAT. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3ab15819524466d41b2114dc91630edc0c"></a>ArcSinH&#160;</td><td class="fielddoc"><p>The ArcSinH function (inverse hyperbolic sine function). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3aceffe7f812563934924b8dd08a319fc7"></a>ArcTan&#160;</td><td class="fielddoc"><p>The ArcTan function (inverse tangent function). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3abb7ba525e0c40179fab22b4f7021e1f8"></a>LeakyReLU&#160;</td><td class="fielddoc"><p>Leaky rectified linear activation unit (ReLU). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3abf418518814d00feae3c57abdb42ed33"></a>LeakyReLUShifted&#160;</td><td class="fielddoc"><p>Leaky rectified linear activation unit (ReLU). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a9a2126552a9de60d20d95a47f85a16fd"></a>Logistic&#160;</td><td class="fielddoc"><p>The logistic function. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3af332fa7e3bdba9d6626b2b0fa81ff750"></a>LogisticApproximantSteep&#160;</td><td class="fielddoc"><p>The logistic function with a steepened slope, and implemented using a fast to compute approximation of exp(). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a2aec9459f1ea9e144c3df7f96a2a080d"></a>LogisticSteep&#160;</td><td class="fielddoc"><p>The logistic function with a steepened slope. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a185bbed8eed73247c37f61fe6af0c73a"></a>MaxMinusOne&#160;</td><td class="fielddoc"><p>max(-1, x,) function. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a7ee44e8257ec8046f96bb86a6c5837ec"></a>NullFn&#160;</td><td class="fielddoc"><p>Null activation function. Returns zero regardless of input. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a07cade9a2910a2401165771a815bb7bd"></a>PolynomialApproximantSteep&#160;</td><td class="fielddoc"><p>A very close approximation of the logistic function that avoids use of exp() and is therefore typically much faster to compute, while giving an almost identical sigmoid curve. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a42dfb5214fde625aa0b9daa25fa48745"></a>QuadraticSigmoid&#160;</td><td class="fielddoc"><p>A sigmoid formed by two sub-sections of the y=x^2 curve. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3add10d919fa85cf27fc78c0e06fe0b378"></a>ReLU&#160;</td><td class="fielddoc"><p>Rectified linear activation unit (ReLU). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a507397d2e79e077181748788413cf0e1"></a>ScaledELU&#160;</td><td class="fielddoc"><p>Scaled Exponential Linear Unit (SELU). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a9a2993b063c53c9152efc379d854233c"></a>SoftSignSteep&#160;</td><td class="fielddoc"><p>The softsign sigmoid. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3aa56102aa4851a1dbb5279c6a73b3c439"></a>SReLU&#160;</td><td class="fielddoc"><p>S-shaped rectified linear activation unit (SReLU). </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a47015ed4ddc5087547e16930ddfce10e"></a>SReLUShifted&#160;</td><td class="fielddoc"><p>S-shaped rectified linear activation unit (SReLU). Shifted on the x-axis so that x=0 gives y=0.5, in keeping with the logistic sigmoid. </p>
</td></tr>
<tr><td class="fieldname"><a id="a27ff9f8b81855c4d5fc8cef8b0f72de3a23b68da1de2b77d74da9da2635722a3e"></a>TanH&#160;</td><td class="fielddoc"><p>TanH function (hyperbolic tangent function). </p>
</td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="a07799c995b8a60aa890f0ed13957ea5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a07799c995b8a60aa890f0ed13957ea5f">&#9670;&nbsp;</a></span>VecFn&lt; T &gt;()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">delegate void SharpNeat.NeuralNet.VecFn&lt; T &gt; </td>
          <td>(</td>
          <td class="paramtype">T[]&#160;</td>
          <td class="paramname"><em>v</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Vectorized activation function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">v</td><td>A vector of pre-activation levels to pass through the function. The resulting post-activation levels are written back to this array/vector.</td></tr>
  </table>
  </dd>
</dl>
<div class="typeconstraint">
<dl><dt><b>Type Constraints</b></dt><dd>
<table border="0" cellspacing="2" cellpadding="0">
<tr><td valign="top"><em>T</em></td><td>&#160;:</td><td valign="top"><em>struct</em></td><td>&#160;</td></tr>
</table>
</dd>
</dl>
</div>

</div>
</div>
<a id="ad5f51a21485ae71aeec537c68ab11026"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad5f51a21485ae71aeec537c68ab11026">&#9670;&nbsp;</a></span>VecFnSegment2&lt; T &gt;()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">delegate void SharpNeat.NeuralNet.VecFnSegment2&lt; T &gt; </td>
          <td>(</td>
          <td class="paramtype">double[]&#160;</td>
          <td class="paramname"><em>v</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double[]&#160;</td>
          <td class="paramname"><em>w</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>startIdx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>endIdx</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Vectorized activation function with activity limited to a defined sub-range/segment of the vector, and post-activation levels stored in a separate supplied vector. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">v</td><td>A vector of pre-activation levels to pass through the function. <dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">w</td><td>A vector in which the post activation levels are stored.</td></tr>
  </table>
  </dd>
</dl>
The resulting post-activation levels are written back to this array/vector.</td></tr>
    <tr><td class="paramname">startIdx</td><td>Start index.</td></tr>
    <tr><td class="paramname">endIdx</td><td>End index (exclusive).</td></tr>
  </table>
  </dd>
</dl>
<div class="typeconstraint">
<dl><dt><b>Type Constraints</b></dt><dd>
<table border="0" cellspacing="2" cellpadding="0">
<tr><td valign="top"><em>T</em></td><td>&#160;:</td><td valign="top"><em>struct</em></td><td>&#160;</td></tr>
</table>
</dd>
</dl>
</div>

</div>
</div>
<a id="a24d800421b54ea3542656b8139caa263"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24d800421b54ea3542656b8139caa263">&#9670;&nbsp;</a></span>VecFnSegment&lt; T &gt;()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">delegate void SharpNeat.NeuralNet.VecFnSegment&lt; T &gt; </td>
          <td>(</td>
          <td class="paramtype">double[]&#160;</td>
          <td class="paramname"><em>v</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>startIdx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>endIdx</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Vectorized activation function with activity limited to a defined sub-range/segment of the vector. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">v</td><td>A vector of pre-activation levels to pass through the function. The resulting post-activation levels are written back to this array/vector.</td></tr>
    <tr><td class="paramname">startIdx</td><td>Start index.</td></tr>
    <tr><td class="paramname">endIdx</td><td>End index (exclusive).</td></tr>
  </table>
  </dd>
</dl>
<div class="typeconstraint">
<dl><dt><b>Type Constraints</b></dt><dd>
<table border="0" cellspacing="2" cellpadding="0">
<tr><td valign="top"><em>T</em></td><td>&#160;:</td><td valign="top"><em>struct</em></td><td>&#160;</td></tr>
</table>
</dd>
</dl>
</div>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespace_sharp_neat.html">SharpNeat</a></li><li class="navelem"><a class="el" href="namespace_sharp_neat_1_1_neural_net.html">NeuralNet</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
